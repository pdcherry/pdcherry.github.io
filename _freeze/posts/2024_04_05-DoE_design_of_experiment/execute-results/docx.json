{
  "hash": "5726ea7a8796284059b32812cb9e1ae7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"DoE: Design of Experiment\"\nauthor: \"Patrick Cherry\"\ndate: \"2024-04-05\"\ncategories:\n  - DoE\n  - design of experiment\n  - code\n  - science\nimage: \"2024_04_05-DoE_architecture_imperfect_grid.jpg\"\nbibliography: 2024_04_05-DoE_design_of_experiment.bib\nfrom: markdown+tex_math_single_backslash\nformat:\n  html:\n    df-print: paged\nexecute:\n  freeze: TRUE\n  echo: FALSE\neditor_options: \n  chunk_output_type: inline\n---\n\n\n\n![DoE experiments can make conclusions that are greater than the sum of its parts, through thoughtful designs. Much like an architectural facade, DoEs often employ a grid of conditions that do not perfectly sample every possible combination. Image credit: seier+seier on Flickr under CC](2024_04_05-DoE_architecture_imperfect_grid.jpg)\n\n> To consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of.\n> â€” Ronald A. Fisher\n> First Session of the Indian Statistical Conference, Calcutta, 1938\n> [@OxfordEssentialQuotations]\n\n## Introduction and motivation\nIn this post, I describe an experimental design for generating a genomics dataset using statistical DoE principles.\n\nMy motivation for designing and carrying out this experiment was that I had data showing the sensitivity (by percent recall of a set of genetic variants expressed as mRNAs) over a controlled range of concentrations (made by serial dilution). *However, those data were only gathered with one target enrichment panel, which was a fairly esoteric TE Panel.* The goal was to extend the conclusions on sensitivity and recall to other, more mainstream panels used in RNA-seq experiments. We'll call the esoteric panel \"Panel A.\" I had the idea that, given the success Panel A's bioinformatic performance, *it could be useful to show that many different TE panels work well for an extension of said bioinformatic performance*, encouraging the use of those other panels by showing equal analytical performance in a head-to-head experiment.\n\nTo do so, I proposed using multiplexed capture (to save on wet-lab resources and time), 100 ng of input RNA (and optionally 10 ng), and technical replicates (n = 3, or a minimum of n = 2 for dropout protection). These are parameterized in this DoE script below, and the resulting sample plan is exported to google sheets for directing the lab activities a team of scientists and research associates.\n\n### Historical roots of design of experiment\nBritish statistician and geneticist Ronald A. Fisher (1890-1962) heavily influenced the modern ideals of experimental design. His influential 1922 publication on maximum likelihood laid the groundwork for now widely-taught concepts of sufficiency, information, and efficiency [@Fisher1922]. Fisher also pioneered and developed the methods of study randomization, and he promoted principles of *design of experiment* [@Edwards1974]. The radical idea (at the time) was that designs could be based on varying multiple factors simultaneously, and the downstream analysis could be supported by multi-factor analysis of variance. This progress in design and analysis allowed for the testing of many variables and factors in one experiment (when designed properly) instead of many one-by-one factor comparisons.\n\n## Brief intro to DoE concepts\nBelow, I provide a glossary of design of experiment (DoE) concepts and their definitions. After, I describe which apply to here, and how I incorporated that concept into the design.\n\n - *Independent variable*: Also called treatment factor, it is a variable under study as a potential cause, and so it is controlled at or near some target value, as informed by the hypothesis. An experiment can have more than one independent variable; it is common to analyze multiple independent variables at the same time.\n - *Background variable*: Also called a *lurking variable*, it is a variable that the experimenter is not aware exists or affects the outcome of the experiment. Due to this lack of awareness, it is not controlled. In a well-planned experiment, lurking variables should balance out in effect so as not to impact the conclusion of the experiment.\n - *Dependent variable*: Also called a *response variable*, it is the outcome or output measured from the experiment. An experiment can have multiple dependent variables, but it is more typical to analyze for one of these variables at a time.\n - *Replicate*: additional runs of the same experiment (same treatment, same controls, etc.). Replicates help to understand the within-condition variability of outcomes, and decide if enough evidence is present to conclude the independent variable is _causing_ a change in the response variable.\n - *Confounded factors*: *Confounding* is a relationship of two or more factors to each other. Two or more factors are confounded when they are *auto-correlated* in the design -- that is, when the levels / values of each factor co-occur throughout the experiment --to the exclusion of other combinations of levels of those factors. In this situation, it is impossible to provide evidence for which factor causes any observed change in the response variable. (Some analyses will emit an error or a warning when confounding or autocorrelation of independent variable occurs.)\n - *Biased factor*: *Bias* in another relationship between experimental factors. Bias occurs when an experimenter makes a change to an independent variable at the precise time when changes in a lurking variable also occur. This is effectively confounding with a lurking variable, but because lurking variables are not always known or measured, the situation can go undetected, which can lead to erroneous conclusions. For this reason, it can be good to measure suspected lurking variables *even if they are not controlled* for retrospective analysis of bias.\n - *Experimental error*: the difference between the measured response for a condition and the long-run average of that condition. In this definition, error is a statistical measure, and not literally a \"mistake\" or \"inaccuracy,\" as synonyms for error suggest. Experimental error is expected (to some degree) because background or lurking variables can subtly influence outcomes or measurements.\n - *Randomization*: the random assignment of conditions to a particular sample of an experiment, which leads to the likely reduction of experimental error.\n - *Blocking*: the spreading of all other variables as evenly as is practical over the variable in question. If a variable is suspected of being a lurking variable, it can be \"blocked\" in the experimental design, which spreads its bias (if any) as evenly as is practical across all other combinations of factors. This even spreading allows for a bias in the blocked variable to be detected with high precision in analysis.\n\nExperimental error is subdivided into __bias error__ and __random error__:\n\n  - *Bias error* tends to remain constant or change in a consistent pattern over time or with other variables (whether measured or not).\n  - *Random error* changes from one experiment to another unpredictably. However, it the long run, random error averages to zero and has a consistent probability distribution that allows us to draw conclusions.\n\n### Aplying DoE principle to this experiment\nRandomization is a good way to get random error to cancel out within an experiment. Any one randomized experiment that suffers (by chance) from a preponderance of random error will not replicate that random error in a repeat experiment, because the randomization will change, and likely distribute the error differently across samples. Thus, randomization is effective for preventing error from confounding experimental conclusion in the long term.\n\nBut what if we want to prevent error from affecting *this experiment*? If we have a hypothesized source of the bias in mind, then we can deploy a *randomized complete block* design, also known as using blocking on a variable.\n\nIf we have a suspected influence from a variable that we're not testing as an independent variable, we can attempt to minimize the contribution of its effect (or bias) to the experimental conclusions.\n\n## Procedure\n\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanel_info <- tribble(\n  ~panel,  ~panel_size,  ~needed_sequencing,\n  \"TE Panel A\", 3.0, NA,\n  \"TE Panel B\",  36.8, NA,\n  \"TE Panel C\",  35.8, NA,\n  \"Whole Transcriptome\", NA, NA)\n```\n:::\n\n\n\n\n## DoE with blocking for multiple operators\nI will block for the operators carrying out library prep, because operator is a known source of variation that is not relevant to understanding the effect of TE panel, RNA input mass, or concentration on performance. (For example, my direct report is better at target enrichment than I am--she gets better fold-80 scores and off-target percentages than me routinely. But we're here to study *the panels*, not the operators, and we need to share the work.)\n\nBlocking is the non-random assignment of samples to groups to minimize differences in the sample composition between the groups such that any effect of the grouping can be determined by the model and ignored (modeled out quantitatively and precisely).\n\n\n\n\n\n\n\n\n\nThe `optBlock` function from the `AlgDesign` package is maximizing $|X'X|$, the determinant of the product of the inverse of the design matrix and the design matrix, a process called *D-optimization*. (The D criterion minimizes the overall variance of the estimates during analysis.) [@Donev1988] Further explanation is beyond the scope of this tutorial, but is available in copious detail in the documentation of the `AlgDesign` package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE_sensitivity_doe$D;\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3789291\n```\n\n\n:::\n\n```{.r .cell-code}\nrna_TE_sensitivity_doe$diagonality\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.871\n```\n\n\n:::\n:::\n\n\n\n\nDiagonality is the degree to which the blocked variables are uncorrelated: a diagonality of 1.0 is perfectly uncorrelated. A value of 0.871 is moderate. We are getting values less than 1.0, because not every number of unique sample ( 2 * 4 * ~~5~~ ) factors to be processed is divisible by the number of blocking groups. We will see this effect illustrated in the \"Check orthogonality of blocking\" section.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE__blocking_df <- purrr::map(names(rna_TE_sensitivity_doe$Blocks),\n                        ~ rna_TE_sensitivity_doe$Blocks[[.x]]) %>%\n  bind_rows(.id = \"operator\") %>%\n  as_tibble() %>%\n  mutate(\"operator\" = LETTERS[as.integer(operator)],\n         \"operator\" = paste(\"Operator\", operator)) %>%\n  arrange(panel, conc, mass_input)\n```\n:::\n\n\n\n\nAbove, for each block, we bind the rows together into one data frame, converting the block names to the intended use, which is specifying which operator is working. Then arrange the data by panel name, concentration, and mass input.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(panels_to_join <- rna_TE__blocking_df %>%\n  distinct(panel) %>%\n   bind_cols(rename(panel_info, \"panel_name\" = 1)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 Ã— 4\n  panel panel_name          panel_size needed_sequencing\n  <fct> <chr>                    <dbl> <lgl>            \n1 1     TE Panel A                 3   NA               \n2 2     TE Panel B                36.8 NA               \n3 3     TE Panel C                35.8 NA               \n4 4     Whole Transcriptome       NA   NA               \n```\n\n\n:::\n:::\n\n\n\n\nAbove, we prepare the panel info for joining.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(fusconcs_to_join <- rna_TE__blocking_df %>%\n  distinct(conc) %>%\n  bind_cols(concentrations) %>%\n  rename(\"concentrations\" = 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 Ã— 2\n   conc concentrations\n  <dbl> <fct>         \n1    -2 0.027         \n2    -1 0.0027        \n3     0 0.00027       \n4     1 2.7e-05       \n5     2 2.7e-06       \n```\n\n\n:::\n:::\n\n\n\n\nAs well as preparing the concentration info for joining.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(massinput_to_join <- rna_TE__blocking_df %>%\n  distinct(mass_input) %>%\n  bind_cols(mass_inputs) %>%\n  rename(\"mass_inputs\" = 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  mass_input mass_inputs\n       <dbl> <fct>      \n1         -1 10         \n2          1 100        \n```\n\n\n:::\n:::\n\n\n\n\nAnd lastly prepare the mass input levels for joining.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE__doe_blocked <- rna_TE__blocking_df %>%\n  left_join(panels_to_join, by = \"panel\") %>%\n  left_join(fusconcs_to_join, by = \"conc\") %>%\n  left_join(massinput_to_join, by = \"mass_input\") %>%\n  select(\"panel\" = \"panel_name\", \"conc\" = \"concentrations\",\n         \"mass_input\" = \"mass_inputs\", \"operator\", panel_size, needed_sequencing) %>%\n  arrange(panel, desc(conc), mass_input) %>%\n  mutate(\"replicate_num\" = row_number(), .by = c(panel, conc, mass_input)) %>%\n  relocate(replicate_num, .after = operator) %>%\n  rename(\"LP_operator\" = \"operator\") %>%\n  arrange(panel, mass_input) %>%\n  # below, assign samples to captures in plexity of up to 6\n  # the table is sorted in order of panel and mass input, so most of the time,\n  # samples will be paired with other samples with the same mass input, which is\n  # best practice.\n  mutate(\"capture\" = ceiling(row_number()/6) ) %>%\n  relocate(\"capture\", .after = replicate_num) %>%\n  arrange(panel, desc(conc), mass_input)\nhead(rna_TE__doe_blocked, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 Ã— 8\n   panel      conc   mass_input LP_operator replicate_num capture panel_size\n   <chr>      <fct>  <fct>      <chr>               <int>   <dbl>      <dbl>\n 1 TE Panel A 0.027  10         Operator A              1       1          3\n 2 TE Panel A 0.027  10         Operator B              2       1          3\n 3 TE Panel A 0.027  10         Operator B              3       1          3\n 4 TE Panel A 0.027  100        Operator B              1       3          3\n 5 TE Panel A 0.027  100        Operator B              2       3          3\n 6 TE Panel A 0.027  100        Operator B              3       3          3\n 7 TE Panel A 0.0027 10         Operator A              1       1          3\n 8 TE Panel A 0.0027 10         Operator A              2       1          3\n 9 TE Panel A 0.0027 10         Operator A              3       1          3\n10 TE Panel A 0.0027 100        Operator A              1       4          3\n# â„¹ 1 more variable: needed_sequencing <lgl>\n```\n\n\n:::\n:::\n\n\n\n\nAbove, we interpret the numeric levels from the DoE by joining each to the tables that provide the literal values for those experimental variables.\n\nAbove, we also assigned samples to captures in plexity of up to 6 the table is sorted in order of panel and mass input, so most of the time, samples will be paired with other samples with the same mass input, which is best practice.\n\nQuickly spot-checking the first 10 rows, everything looks reasonable.\n\n### Check orthogonality of blocking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE__doe_blocked %>% count(LP_operator, mass_input)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 Ã— 3\n  LP_operator mass_input     n\n  <chr>       <fct>      <int>\n1 Operator A  10            30\n2 Operator A  100           30\n3 Operator B  10            30\n4 Operator B  100           30\n```\n\n\n:::\n:::\n\n\n\n\nAbove, we count how many samples are operated by each operator at each mass level. The counts are all equal, meaning the two `mass_input` factor levels have been \"spread evenly\" across the available operators.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE__doe_blocked %>% count(LP_operator, panel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 Ã— 3\n  LP_operator panel                   n\n  <chr>       <chr>               <int>\n1 Operator A  TE Panel A             15\n2 Operator A  TE Panel B             15\n3 Operator A  TE Panel C             15\n4 Operator A  Whole Transcriptome    15\n5 Operator B  TE Panel A             15\n6 Operator B  TE Panel B             15\n7 Operator B  TE Panel C             15\n8 Operator B  Whole Transcriptome    15\n```\n\n\n:::\n:::\n\n\n\n\nThe same is true for the levels of the `panel` factor: they have been \"spread evenly\" across the available operators.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE__doe_blocked %>% count(LP_operator, conc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 Ã— 3\n   LP_operator conc        n\n   <chr>       <fct>   <int>\n 1 Operator A  2.7e-06    13\n 2 Operator A  2.7e-05    12\n 3 Operator A  0.00027     9\n 4 Operator A  0.0027     14\n 5 Operator A  0.027      12\n 6 Operator B  2.7e-06    11\n 7 Operator B  2.7e-05    12\n 8 Operator B  0.00027    15\n 9 Operator B  0.0027     10\n10 Operator B  0.027      12\n```\n\n\n:::\n:::\n\n\n\n\nFinally, with RNA concentration, we see that not exactly every operator has the same number of samples at each level of RNA concentration being tested. This is because the number is not evenly divisible, and so some variability in the number of assigned samples will have to exist. Qualitatively, they look reasonably evenly-spread from across the two operators.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngooglesheets4::write_sheet(rna_TE__doe_blocked, ss = \"sheet_string_goes_here\",\n                           sheet = \"rna_TE_sensitivity_doe\");\nfile_dest_dir <- \"doe_design_of_experiment_with_library_prep_files\"\nfs::dir_create(file_dest_dir);\nwrite_csv(rna_TE__doe_blocked, paste0(file_dest_dir, \"/\",\n                                      file_pref,\n                                      \"_rna_TE_sensitivity_doe.csv\"))\n```\n:::\n\n\n\n\nOut put the design to google sheets, where the scientists and research associates can view the experiment's sample plan.\n\n### Analyze captures\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrna_TE__doe_blocked %>%\n  count(capture, panel, mass_input)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 24 Ã— 4\n   capture panel      mass_input     n\n     <dbl> <chr>      <fct>      <int>\n 1       1 TE Panel A 10             6\n 2       2 TE Panel A 10             6\n 3       3 TE Panel A 10             3\n 4       3 TE Panel A 100            3\n 5       4 TE Panel A 100            6\n 6       5 TE Panel A 100            6\n 7       6 TE Panel B 10             6\n 8       7 TE Panel B 10             6\n 9       8 TE Panel B 10             3\n10       8 TE Panel B 100            3\n# â„¹ 14 more rows\n```\n\n\n:::\n:::\n\n\n\n\nAbove, we can see that, for as many samples as possible, libraries with the same total RNA input mass are captured together in the same multiplexed hybridization reaction. In some cases, we see up to three 10 ng input libraries being co-hybridized with 100 ng input libraries. Given the number of samples we want to run and the division of different TE panels, this is the best we can do.\n\n## Conclusion\nGreat! We have an experiment design for testing the effect of these panels against each other and against whole transcriptome sequencing. The experiment had n = 3 replicates, and it is blocked for having two operators carry out the RNA-seq library preps.\n\nImportantly, when I get feedback on the design of this sample layout, I can easily show my work. Even better, if changes are needed, the entire design is programmed, and can be changed in seconds.\n\nLet's get this experiment started.\n\n\n\n\n---\nnocite: |\n  @fedorov1972optimal\n---\n",
    "supporting": [
      "2024_04_05-DoE_design_of_experiment_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}