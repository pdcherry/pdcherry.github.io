---
title: "emmeans: estimated marginal means"
author: "Patrick Cherry"
date: "xxxx-xx-xx"
categories:
  - data
  - code
  - experimental analysis
  - unbalanced DoE
#image: "2024_02_10-SF_tree_class_data_data/"
# PATRICK TO DO: FIND UNBALANCED THEME IMAGE
format:
  html:
    df-print: kable
execute:
  freeze: TRUE
  echo: TRUE
editor_options: 
  chunk_output_type: inline
---
```{r echo = FALSE}
caption_def <- "2024-05-01 emmeans estimated marginal means"
exp_imp_path <- "./2024-03-10_emmeans_data/"
```

```{r, setup, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)  # set default chunk option to print the code that generated that output
#options(knitr.table.format = 'markdown') # render kable tables in md for github, comment out otherwise
library(tidyverse)
library(broom)
library(emmeans)
library(patchwork)                  # for combining plots
library(modelbased)                 # https://easystats.github.io/modelbased/articles/estimate_means.html
```

# Introduction to marginal means
Estimated marginal means (EMMs, previously known as least-squares means in the context of traditional regression models) are derived by using a model to make predictions over a regular grid of predictor combinations (called a reference grid).

There are many advantages to using estimated marginal means to arrive at effect sizes (as well as confidence intervals) for a multi-factor / multi-level experiment.

  1. One challenge where EMMs really shines is when the number of subjects / samples per condition are not all the same or close to the same; this situation is called an "unbalanced experiment," and it occurs often during large Design of Experiment (DoE), either intentionally by design, or unintentionally due to experimental sample drop outs. EMMs can provide accurate estimates of means and standard errors (confidence intervals) for conditions that differ in sample size, such that, all else equal, conditions with a smaller _n_ have larger confidence intervals.
  1. Another is when there is a hypothesized (or evident) interaction effect in either the mean or the spread of one or more conditions in the experiment. EMMs can estimate accurate relative effects and standard errors (confidence intervals) for each of those interactions.

# The pigs dataset
Consider the pigs dataset provided with the package (`help("pigs")` provides details). These data come from an experiment where pigs are given different percentages of protein (percent) from different sources (source) in their diet, and later we measured the concentration (conc) of the amino acid leucine. The percent values are quantitative, but we chose those particular values deliberately (like a DoE), and (at least initially) we want separate estimates at each percent level; that is, we want to view percent as a factor, not a quantitative predictor.

## Initial model fitting
Our first task is to come up with a good model. Doing so requires a lot of skill, and we don’t want to labor too much over the details; you really need other references to deal with this aspect adequately. But we will briefly discuss five models and settle on one of them:
```{r, warning = FALSE}
mod1 <- lm(conc ~ source * factor(percent), data = pigs)
par(mfrow = c(2,2)); plot(mod1)
```
```{r}
mod2 <- update(mod1, . ~ source + factor(percent))   # no interaction
par(mfrow = c(2,2)); plot(mod2)
```

```{r}
map_dfr(list(mod1, mod2), glance)
```


These models have R2 values of 0.808 and 0.700, and adjusted R2 values of 0.684 and 0.634. mod1 is preferable to mod2, suggesting we need the interaction term. However, a residual-vs-predicted plot of mod2 has a classic “horn” shape (curving and fanning out), indicating a situation where a response transformation might help better than including the interaction.

After trial and error, it turns out that an inverse (reciprocal) transformation, (1/conc) really serves well. (Perhaps this isn’t too surprising, as concentrations are typically determined by titration, in which the actual measurements are volumes of some counter-reactant; and these are reciprocally related to concentrations, i.e., amounts per unit volume.)

So here are three more models:
```{r}
mod3 <- update(mod1, inverse(conc) ~ .)
mod4 <- update(mod2, inverse(conc) ~ .)     # no interaction
mod5 <- update(mod4, . ~ source + percent)  # linear term for percent
par(mfrow = c(2,2)); plot(mod5)
```

```{r}
map_dfr(list(mod1, mod2, mod3, mod4, mod5), glance)
```
(Note: We could have used 1/conc as the response variable, but emmeans provides an equivalent inverse() function that will prove more advantageous later.) The residual plots for these models look a lot more like a random scatter of points (and that is good). The R2 values for these models are 0.818, 0.787, and 0.749, respectively; and the adjusted R2s are 0.700, 0.740, and 0.719. mod4 has the best adjusted R2 and will be our choice.

# Estimated marginal means
```{r}
(EMM.source <- emmeans(mod4, "source"))
```

```{r}
(EMM.percent <- emmeans(mod4, "percent"))
```

Calling `tidy()` (from `broom`) on the object will put it into a beautiful data frame. we could make a plot.

```{r}
tidy(EMM.percent)
```


## Comparison to ordinary means
Let’s compare these with the ordinary marginal means (OMMs) on inverse(conc):

```{r}
with(pigs, tapply(inverse(conc), source, mean))
```

Can I write the above ordinary means in Tidyverse/dplyr language? 
```{r}
pigs %>%
  mutate(conc = 1/conc) %>%
  summarize(mean = mean(conc), .by = source)
```

```{r}
with(pigs, tapply(inverse(conc), percent, mean))
```

```{r}
pigs %>%
  mutate(conc = 1/conc) %>%
  summarize(mean = mean(conc), .by = percent)
```

Both sets of OMMs are vaguely similar to the corresponding EMMs. However, please note that the EMMs for percent form a decreasing sequence, while the the OMMs decrease but then increase at the end.

# The reference grid, and definition of EMMs

Estimated marginal means are defined as marginal means of model predictions over the grid comprising all factor combinations – called the reference grid. For the example at hand, the reference grid is

```{r}
(RG <- expand.grid(source = levels(pigs$source), percent = unique(pigs$percent)))
```

To get the EMMs, we first need to obtain predictions on this grid:

```{r}
(preds <- matrix(predict(mod4, newdata = RG), nrow = 3))
```

then obtain the marginal means of these predictions:
```{r}
apply(preds, 1, mean)   # row means -- for source
```

```{r}
apply(preds, 2, mean)   # column means -- for percent
```

These marginal averages match the EMMs obtained earlier via `emmeans()`.

Now let’s go back to the comparison with the ordinary marginal means. The source levels are represented by the columns of pred; and note that each row of pred is a decreasing set of values. So it is no wonder that the marginal means – the EMMs for source – are decreasing. That the OMMs for percent do not behave this way is due to the imbalance in sample sizes:

```{r}
with(pigs, table(source, percent))
```

This shows that the OMMs of the last column give most of the weight (3/5) to the first source, which tends to have higher inverse(conc), making the OMM for 18 percent higher than that for 15 percent, even though the reverse is true with every level of source. This kind of disconnect is an example of Simpson’s paradox, in which a confounding factor can distort your findings. The EMMs are not subject to this paradox, but the OMMs are, when the sample sizes are correlated with the expected values.

In summary, we obtain a references grid of all factor combinations, obtain model predictions on that grid, and then the expected marginal means are estimated as equally-weighted marginal averages of those predictions. Those EMMs are not subject to confounding by other factors, such as might happen with ordinary marginal means of the data. Moreover, unlike OMMs, EMMs are based on a model that is fitted to the data.

