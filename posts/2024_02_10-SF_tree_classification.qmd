---
title: "San Francisco tree classification model"
author: "Patrick Cherry"
date: "2024-02-10"
categories:
  - data
  - code
  - tree models
image: "2024_02_10-SF_tree_classification.jpg"
format:
  html:
    df-print: paged
execute:
  freeze: TRUE
  echo: TRUE
editor_options: 
  chunk_output_type: inline
---

```{r echo = FALSE}
caption_def <- "2024-02-10 SF Tree Classification"
exp_imp_path <- "./2024_02_10-SF_tree_class_data_data/"
```

![A purple-leaf plum (Prunus cerasifera ‘Krauter Vesuvius’) tree bluming along a hilly San Francisco street](2024_02_10-SF_tree_classification.jpg)

The goal is the make a predictor of whether a tree tracked in San Francisco is a Department of Public Works maintained legal status tree, or some other legal status.

```{r, setup, echo = FALSE, message = FALSE}
library(tidyverse)        # tidyverse plotting, dataframes, etc.
library(tidymodels)       # for managing random forest models
library(themis)           # for step_downsample()
library(vip)              # for model exploration
library(broom)            # for tidy functional programming
theme_set(theme_bw())     # set default ggplot2 theme to cartooney plain
library(patchwork)        # for combining plots
```

# Get data
This is a 2020-01-28 [Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-28/readme.md) dataset. These data are from the San Francisco Public Works' Bureau of Urban Forestry.

```{r}
sftrees <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-28/sf_trees.csv",
                    show_col_types = FALSE)
```

# Preliminary exploration of data
```{r}
head(sftrees)
```

## Legal status
```{r}
sftrees %>%
  count(legal_status, sort = TRUE) %>%
  mutate(percent = round( n / sum(n) * 100, digits = 1))
```

```{r}
sftrees %>% count(legal_status, caretaker, sort = TRUE) %>% head(20)
```

So the `legal_status` of "DPW Maintained" does not equate with a `caretaker` of "DPW"—in fact, most of the time, DPW-legal status trees are privately taken care of.

```{r}
col_plot_legalstatus_by_caretaker <- sftrees %>%
  count(legal_status, caretaker) %>%
  add_count(caretaker, wt = n, name = "caretaker_count") %>%
  filter(caretaker_count > 50) %>%
  group_by(legal_status) %>%
  mutate(percent_legal = n / sum(n)) %>%
  ggplot(aes(percent_legal, caretaker, fill = legal_status)) +
  geom_col(position = "dodge") +
  scale_fill_viridis_d(option = "D", begin = 0.1, end = 0.7, na.value = "grey50") +
  labs(x = "proportion of trees in each category")
col_plot_legalstatus_by_caretaker
```

## NAs in data
```{r}
sftrees %>%
  summarise(across(everything(), ~ sum(is.na(.x))),
            "n" = n()) %>%
  relocate(n) %>%
  t() %>% as_tibble(.name_repair = "minimal", rownames = "col_name")
```

Instead of using `glimpse()`, I'm using R's native `t()`, or transpose, to print the results lengthwise instead of as columns across the page. The `n` row at the start shows how many rows are in the dataframe; the other named columns show how many `NA`s are in the data in each column. The `date` and `dhb` [(Diameter at breast height)](https://en.wikipedia.org/wiki/Diameter_at_breast_height) columns show significant levels of NAs (64.5% and 21.7%, respectively).

## Species
```{r}
sftrees %>% count(species, sort = TRUE) %>%
  mutate("rank" = row_number()) %>% head(20)
```

```{r}
sftrees %>% count(species, sort = TRUE, name = "n_observations") %>%
  count(n_observations, name = "n_tree_species") %>%
  head(10)
```

```{r}
col_plot_tree_species <- sftrees %>%
  count(species) %>%
  filter(n >= 400) %>%
  mutate("species" = fct_rev(fct_infreq(as_factor(species), w = n))) %>%
  ggplot(aes(y = n, x = species, fill = species)) +
  geom_col() +
  scale_fill_viridis_d(option = "D", begin = 0.1, end = 0.7, na.value = "grey50") +
  coord_flip() +
  labs(y = "Number of trees", x = "Species") +
  theme(legend.position = "none",
        axis.text.y = element_text(size = 4))
col_plot_tree_species
```

From this distribution of tree species with 400 or more trees, we can see some species data quality issues. The observation "trees(s)::" for `species` is the most abundant classification, which really isn't a classification at all. The 26th most common species observation is "::", so no data at all.

In this San Francisco data, the most common tree is the Sycamore: London Plane (*Platanus x hispanica*) with 11557. I personally like the Cherry Plum tree (*Prunus cerasifera*), which is 7th with 6716 trees. Interestingly, there are lots of Southern Magnolia trees (*Magnolia grandiflora*), in 8th place with 6285.

Also interestingly, there are 67 tree species with one individual in the data set. And 44 species with just 2 individuals. There are lots of lone or near-lone tree species in San Francisco.

### What about tree family?
We could perhaps call the tree family, or 'spp' based on the final word in the `species` data column.

A lot of common species names end in "tree", so I will accommodate that by writing a special regex that will pull the next to last word if the last word is "tree". Also, some trees are 

```{r}
sftrees %>%
  mutate("tree_family" = str_extract(species, "(\\w+(?=\\s(T|t)ree))|(\\w+)$")) %>%
  # use above regex to get next to last word when last word is tree
  # also, don't keep "tree" text, because some species are coded as both with
  # and without tree at the end; this regex collapses those irregularities
  count(tree_family, sort = TRUE) %>%
  mutate("rank" = row_number()) %>% head(50)
```

Based on pseudo-"family" classification, the Box tree is the most common tree family observed, followed by the Plane, and then Fig, "Xmas," Magnolia, Cheery, Plum, Myrtle, Strawberry, Gum, and Pear families of trees.

## plot_size
```{r}
sftrees %>% count(plot_size, sort = TRUE) %>% head(20)
```

## Prepare data for model
```{r}
trees_formodel <- sftrees %>% #trees_df
  mutate(
    "legal_status" = case_when(
      legal_status == "DPW Maintained" ~ legal_status,
      TRUE ~ "Other"),
    "plot_size" = parse_number(plot_size)) %>%
  select(-address) %>%
  na.omit() %>%
  mutate_if(is.character, factor)

head(trees_formodel)
```

```{r}
col_plot_legalstatus_by_caretaker <- trees_formodel %>%
  count(legal_status, caretaker) %>%
  add_count(caretaker, wt = n, name = "caretaker_count") %>%
  filter(caretaker_count > 50) %>%
  group_by(legal_status) %>%
  mutate(percent_legal = n / sum(n)) %>%
  ggplot(aes(percent_legal, caretaker, fill = legal_status)) +
  geom_col(position = "dodge") +
  scale_fill_viridis_d(option = "D", begin = 0.1, end = 0.7, na.value = "grey50") +
  labs(fill = NULL,
       x = "proportion of trees in each category")
col_plot_legalstatus_by_caretaker
```

## Quick plot/map of data
```{r}
tree_loc_plot <- trees_formodel %>%
  ggplot(aes(x = longitude, y = latitude, color = legal_status)) +
  geom_point(alpha = 0.6, size = 0.25) +
  labs(color = NULL, x = NULL, y = NULL) +
  theme(panel.border = element_blank(),
        legend.position = c(0.1, 0.9), legend.justification = c(0, .5)) +
  scale_color_viridis_d(option = "D", begin = 0.1, end = 0.7)
tree_loc_plot
```

```{r, eval = FALSE, include = FALSE}
ggsave(paste0(exp_imp_path, "-", "tree_loc_plot", ".png"),
       tree_loc_plot, width = 5, height = 4, dpi = 320)
```

## Build Model
```{r}
set.seed(123)
trees_split <-initial_split(trees_formodel, strata = legal_status)
trees_train <- training(trees_split)
trees_test <- testing(trees_split)

nrow(trees_train); nrow(trees_test)
```

## Feature engineering for the date
```{r}
tree_rec <- recipe(legal_status ~ ., data = trees_train) %>%
  update_role(tree_id, new_role = "ID") %>%
  step_other(species, caretaker, threshold = .01) %>%
  step_other(site_info, threshold = .005) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_date(date, features = c("year")) %>%
  step_rm(date) %>%
  step_downsample(legal_status)

tree_prep <- prep(tree_rec)

juiced <- juice(tree_prep)
```

### Review data preprocessing results
```{r}
juiced %>% count(legal_status)
```

# Set up model hyperparameters
```{r}
tune_spec <- rand_forest(
  mtry = tune(), # 
  trees = 1000, # number of trees to start with
  min_n = tune() # how many data points in a node to keep splitting further
) %>%
  set_mode("classification") %>%
  set_engine("ranger")
```

## Set up workflow
convenience functions
```{r}
tune_wf <- workflow() %>%
  add_recipe(tree_rec) %>%
  add_model(tune_spec)
```

## Train-test some model hyperparameters
```{r, eval = FALSE, include = TRUE}
set.seed(234)
trees_folds <- vfold_cv(trees_train)

set.seed(345)
doParallel::registerDoParallel()
tune_res <- tune_grid(
  tune_wf,
  resamples = trees_folds,
  grid = 20)
```

```{r, eval = FALSE, include = FALSE}
saveRDS(tune_res, "../../pdcherry_github_data/2024_02_10-SF_tree_class/2024_02_10-SF_tree_class_tune_res.rds")
```

```{r, eval = TRUE, include = FALSE}
tune_res <- readRDS("../../pdcherry_github_data/2024_02_10-SF_tree_class/2024_02_10-SF_tree_class_tune_res.rds")
```

### view results
```{r}
show_best(tune_res, metric = "accuracy")
```
```{r}
show_best(tune_res, metric = "roc_auc")
```

```{r}
side_facet_n_mtry_plot <- tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")
side_facet_n_mtry_plot
```

```{r}
nonortho_gid_n_mtry_plot <- tune_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  ggplot(aes(x = min_n, y = mtry, color = mean)) +
  geom_point(size = 6) +
  geom_hline(yintercept = 10, linetype = "dotted") +
  geom_hline(yintercept = 30, linetype = "dotted") +
  geom_vline(xintercept = 2, linetype = "dotted") +
  geom_vline(xintercept = 8, linetype = "dotted") +
  scale_color_viridis_c(option = "D") +
  labs(color = "roc_auc")
nonortho_gid_n_mtry_plot
```

While it's not a regular grid (of orthogonal combinations that would allow for *ceteris paribus* testing) of `min_n` and `mtry`, but we can get an idea of what is going on. It looks like higher values of mtry are good (above about 10) and lower values of min_n are good (below about 10). We can get a better handle on the hyperparameters by tuning one more time, this time using regular_grid(). Let’s set ranges of hyperparameters we want to try, (inside of the dotted line box displayed on the 2D plot above) based on the results from our initial tune.

## Train-test some model hyperparameters
```{r}
set.seed(456)

rf_grid <- grid_regular(mtry(range = c(10, 30)),
                        min_n(range = c(2, 8)),
                        levels = 5)

nrow(rf_grid)
```

```{r, eval = FALSE}
set.seed(456)
doParallel::registerDoParallel()
tune_reg_res <- tune_grid(tune_wf,
                          resamples = trees_folds,
                          grid = rf_grid)
```

```{r, eval = FALSE, include = FALSE}
saveRDS(tune_reg_res, "../../pdcherry_github_data/2024_02_10-SF_tree_class/2024_02_10-SF_tree_class_tune_reg_res.rds")
```

```{r, eval = TRUE, include = FALSE}
tune_reg_res <- readRDS("../../pdcherry_github_data/2024_02_10-SF_tree_class/2024_02_10-SF_tree_class_tune_reg_res.rds")
```

### view results
```{r}
tune_reg_res %>% select_best(metric = "accuracy")
```
```{r}
tune_reg_res %>% select_best(metric = "roc_auc")
```

```{r}
grid_n_mtry_plot <- tune_reg_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, linewidth = 1.5) +
  geom_point() +
  labs(title = "Tune AUC by min_n and mtry",
       y = "AUC")
grid_n_mtry_plot
```

```{r}
nonortho_gid_n_mtry_plot <- tune_reg_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  select(mean, min_n, mtry) %>%
  ggplot(aes(x = min_n, y = mtry, color = mean)) +
  geom_point(size = 6) +
  scale_color_viridis_c(option = "D") +
  labs(color = "roc_auc")
nonortho_gid_n_mtry_plot
```

Both 2D plots show that the mtry = 15 and min_n = 2 hyperperamater maximize the AUC for this random forest model.

# Finalize the model
```{r}
best_auc <- tune_reg_res %>% select_best(metric = "roc_auc")
```

```{r}
final_rf <- finalize_model(tune_spec, best_auc)

final_rf
```

## Understand final model
```{r}
final_rf_vip_plot <- final_rf %>%
  set_engine("ranger", importance = "permutation") %>%
  fit(legal_status ~ ., data = select(juiced, -tree_id)) %>%
  vip(geom = "point")
final_rf_vip_plot
```

Satisfyingly, whether the caretaker is private makes a large difference, and latitude and longitide each make a large (and approximately equal) contribution.

# Apply the final model
```{r}
final_wf <- workflow() %>%
  add_recipe(tree_rec) %>%
  add_model(final_rf)

final_result <- final_wf %>% last_fit(trees_split)
```

```{r}
final_result %>% collect_metrics()
```

This is a great result, because it means we did not over fit to the training data set. This is the AUC we can expect for new San Francisco Trees.

## Make predictions
```{r, message = FALSE}
final_result_ano <- final_result %>%
  collect_predictions() %>%
  mutate("correct_prediction" = if_else(legal_status == `.pred_class`, "Correct", "Incorrect")) %>%
  bind_cols(trees_test)

tree_correct_loc_plot <- final_result_ano %>%
  ggplot(aes(x = longitude, y = latitude, color = correct_prediction)) +
  geom_point(alpha = 0.6, size = 0.25) +
  labs(color = NULL, x = NULL, y = NULL) +
  theme(panel.border = element_blank(),
        legend.position = c(0.1, 0.9), legend.justification = c(0, .5)) +
  scale_color_viridis_d(option = "C", begin = 0.1, end = 0.8) +
  coord_equal()
tree_correct_loc_plot
```

There is some degree of spatial bias in the incorrect assignment of legal status of the SF Trees.
